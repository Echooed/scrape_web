{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful Soup is a Python library used for parsing HTML and XML documents. Here is the general syntax for using Beautiful Soup:\n",
    "\n",
    "1. Importing the library:\n",
    "```\n",
    "from bs4 import BeautifulSoup\n",
    "```\n",
    "2. Creating a BeautifulSoup object:\n",
    "```\n",
    "soup = BeautifulSoup(html_string, 'html.parser')\n",
    "```\n",
    "* `html_string` is the string containing the HTML code.\n",
    "* `'html.parser'` is the parser used to parse the HTML code. You can also use `'lxml'` or `'xml'` parsers.\n",
    "\n",
    "3. Finding elements:\n",
    "```\n",
    "soup.find('tag_name')  # finds the first occurrence of the tag\n",
    "soup.find_all('tag_name')  # finds all occurrences of the tag\n",
    "soup.find('tag_name', {'attribute_name': 'attribute_value'})  # finds the first occurrence of the tag with the specified attribute\n",
    "soup.find_all('tag_name', {'attribute_name': 'attribute_value'})  # finds all occurrences of the tag with the specified attribute\n",
    "```\n",
    "* `tag_name` is the name of the HTML tag you want to find.\n",
    "* `attribute_name` and `attribute_value` are the name and value of the attribute you want to filter by.\n",
    "\n",
    "4. Navigating the tree:\n",
    "```\n",
    "soup.parent  # returns the parent element\n",
    "soup.children  # returns a list of child elements\n",
    "soup.next_sibling  # returns the next sibling element\n",
    "soup.previous_sibling  # returns the previous sibling element\n",
    "```\n",
    "5. Modifying the tree:\n",
    "```\n",
    "soup.tag_name.string  # returns the text content of the tag\n",
    "soup.tag_name.text  # returns the text content of the tag, including child elements\n",
    "soup.tag_name.append(new_tag)  # adds a new tag to the end of the tag\n",
    "soup.tag_name.insert(0, new_tag)  # inserts a new tag at the beginning of the tag\n",
    "soup.tag_name.replace_with(new_tag)  # replaces the tag with a new tag\n",
    "```\n",
    "* `new_tag` is the new tag you want to add or replace.\n",
    "\n",
    "6. Extracting data:\n",
    "```\n",
    "soup.get_text()  # returns the text content of the entire document\n",
    "soup.find('tag_name').get_text()  # returns the text content of the specified tag\n",
    "soup.find('tag_name').attrs  # returns a dictionary of the tag's attributes\n",
    "```\n",
    "These are the basic syntax and methods for using Beautiful Soup. You can find more information and examples in the official Beautiful Soup documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The course Python for beginners cost $20\n",
      "The course Python Web Development cost $50\n",
      "The course Python Machine Learning cost $100\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open('home.html', 'r') as html_file:\n",
    "    content =html_file.read()\n",
    "    \n",
    "    soup = BeautifulSoup(content, 'lxml')\n",
    "    course_cards =soup.find_all('div', class_ = 'card-body')\n",
    "    for course in course_cards:\n",
    "        course_price = course.a.text.split()[-1]\n",
    "        print(f'The course {course.h5.text} cost ${course_price[:-1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For practicing, I will scrape data from a job listing website. \n",
    "The details of the extract will \n",
    "\n",
    "- Company name\n",
    "- Job title\n",
    "- Posting date \n",
    "- skills \n",
    "- more details which shows the url to find the job.\n",
    "\n",
    "\n",
    "This is just a simple extraction process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company: Dinab Recruitment Solutions\n",
      "Job Title: Apply for Airport jobs - HR Executive\n",
      "Posting Date: Posted today\n",
      "Skills: Airport Management|Ground Staff|Cabin Crew|Air Hostess|Cargo Operations|Cargo Handling|Logistics Coordinator|Logistics Manager|Air Ticketing\n",
      "More Details: https://www.timesjobs.com/job-detail/apply-for-airport-jobs-hr-executive-airports-airlines-bengaluru-bangalore-hyderabad-secunderabad-mumbai-cochin-kochi-ernakulam-thiruvananthapuram-0-to-3-yrs-jobid-TYPzI__SLASH__gOTw9zpSvf__PLUS__uAgZw==&source=srp\n",
      "\n",
      "Company: Dinab Recruitment Solutions\n",
      "Job Title: Apply for Airport jobs - Logistics Manager\n",
      "Posting Date: Posted today\n",
      "Skills: Airport Management|Ground Staff|Cabin Crew|Air Hostess|Cargo Operations|Cargo Handling|Logistics Coordinator|Logistics Manager|Air Ticketing\n",
      "More Details: https://www.timesjobs.com/job-detail/apply-for-airport-jobs-logistics-manager-airports-airlines-bengaluru-bangalore-hyderabad-secunderabad-mumbai-cochin-kochi-ernakulam-thiruvananthapuram-0-to-3-yrs-jobid-orqE5aCXZLZzpSvf__PLUS__uAgZw==&source=srp\n",
      "\n",
      "Company: Dinab Recruitment Solutions\n",
      "Job Title: Apply for Airport jobs - HR Executive\n",
      "Posting Date: Posted today\n",
      "Skills: Airport Management|Ground Staff|Cabin Crew|Air Hostess|Cargo Operations|Cargo Handling|Logistics Coordinator|Logistics Manager|Air Ticketing\n",
      "More Details: https://www.timesjobs.com/job-detail/apply-for-airport-jobs-hr-executive-airports-airlines-ahmedabad-guwahati-vadodara-nagpur-jaipur-0-to-3-yrs-jobid-72BRcugp7LxzpSvf__PLUS__uAgZw==&source=srp\n",
      "\n",
      "Company: Dinab Recruitment Solutions\n",
      "Job Title: 12th Pass Fresher Apply for Airport Job\n",
      "Posting Date: Posted today\n",
      "Skills: Airport Handling Operation Ground Handling|Ground Staff|customer services|cabin crew|air hostess|flight attendant|Call HR :926 6401233\n",
      "More Details: https://www.timesjobs.com/job-detail/12th-pass-fresher-apply-for-airport-job-airport-job-bengaluru-bangalore-chennai-hyderabad-secunderabad-cochin-kochi-ernakulam-coimbatore-0-to-3-yrs-jobid-TtMKDECBlCNzpSvf__PLUS__uAgZw==&source=srp\n",
      "\n",
      "Company: Dinab Recruitment Solutions\n",
      "Job Title: 12th Pass Fresher Apply for Airport Job\n",
      "Posting Date: Posted today\n",
      "Skills: Airport Handling Operation Ground Handling|Ground Staff|customer services|cabin crew|air hostess|flight attendant|Call HR :926 6401233\n",
      "More Details: https://www.timesjobs.com/job-detail/12th-pass-fresher-apply-for-airport-job-airport-job-kanniyakumari-madurai-salem-trichy-vellore-0-to-3-yrs-jobid-LY__PLUS__QtCAMv6BzpSvf__PLUS__uAgZw==&source=srp\n",
      "\n",
      "Company: Dinab Recruitment Solutions\n",
      "Job Title: 12th Pass Fresher Apply for Airport Job\n",
      "Posting Date: Posted today\n",
      "Skills: Airport Handling Operation Ground Handling|Ground Staff|customer services|cabin crew|air hostess|flight attendant|Call HR :926 6401233\n",
      "More Details: https://www.timesjobs.com/job-detail/12th-pass-fresher-apply-for-airport-job-airport-job-belgaum-dharwad-hubli-mangalore-mysoru-mysore-0-to-3-yrs-jobid-FcLMrjY1ZUlzpSvf__PLUS__uAgZw==&source=srp\n",
      "\n",
      "Company: Dinab Recruitment Solutions\n",
      "Job Title: 12th Pass Fresher Apply for Airport Job\n",
      "Posting Date: Posted today\n",
      "Skills: Airport Handling Operation Ground Handling|Ground Staff|customer services|cabin crew|air hostess|flight attendant|Hr9266325973\n",
      "More Details: https://www.timesjobs.com/job-detail/12th-pass-fresher-apply-for-airport-job-airport-job-kolkata-surat-jammu-indore-lucknow-0-to-3-yrs-jobid-DItc4cGOrPRzpSvf__PLUS__uAgZw==&source=srp\n",
      "\n",
      "Company: Dinab Recruitment Solutions\n",
      "Job Title: 12th Pass Fresher Apply for Airport Job\n",
      "Posting Date: Posted today\n",
      "Skills: Airport Handling Operation Ground Handling|Ground Staff|customer services|cabin crew|air hostess|flight attendant|Hr9266325973\n",
      "More Details: https://www.timesjobs.com/job-detail/12th-pass-fresher-apply-for-airport-job-airport-job-mumbai-pune-ahmedabad-nagpur-nasik-0-to-3-yrs-jobid-F65LQx7rvMJzpSvf__PLUS__uAgZw==&source=srp\n",
      "\n",
      "Company: Dinab Recruitment Solutions\n",
      "Job Title: 2024 Fresher Hiring Terminal 2\n",
      "Posting Date: Posted today\n",
      "Skills: Airport Handling Operation Ground Handling|Ground Staff|customer services|cabin crew|air hostess|flight attendant|Call HR :926 6401233\n",
      "More Details: https://www.timesjobs.com/job-detail/2024-fresher-hiring-terminal-2-airport-job-bengaluru-bangalore-chennai-hyderabad-secunderabad-cochin-kochi-ernakulam-coimbatore-0-to-3-yrs-jobid-gOdoSyIuNLFzpSvf__PLUS__uAgZw==&source=srp\n",
      "\n",
      "Company: Dinab Recruitment Solutions\n",
      "Job Title: Tamil Nadu Airlines Hiring\n",
      "Posting Date: Posted today\n",
      "Skills: Airport Handling Operation Ground Handling|Ground Staff|customer services|cabin crew|air hostess|flight attendant|Call HR :926 6401233\n",
      "More Details: https://www.timesjobs.com/job-detail/tamil-nadu-airlines-hiring-airport-job-chennai-kanniyakumari-madurai-salem-trichy-0-to-3-yrs-jobid-C9fd0EzIDBVzpSvf__PLUS__uAgZw==&source=srp\n",
      "\n",
      "Company: Dinab Recruitment Solutions\n",
      "Job Title: Karnataka Airlines Hiring\n",
      "Posting Date: Posted today\n",
      "Skills: Airport Handling Operation Ground Handling|Ground Staff|customer services|cabin crew|air hostess|flight attendant|Call HR :926 6401233\n",
      "More Details: https://www.timesjobs.com/job-detail/karnataka-airlines-hiring-airport-job-belgaum-dharwad-hubli-mangalore-mysoru-mysore-0-to-3-yrs-jobid-PoH42xyTe7xzpSvf__PLUS__uAgZw==&source=srp\n",
      "\n",
      "Company: Dinab Recruitment Solutions\n",
      "Job Title: 2024 Fresher Hiring Terminal 2\n",
      "Posting Date: Posted today\n",
      "Skills: Airport Handling Operation Ground Handling|Ground Staff|customer services|cabin crew|air hostess|flight attendant|Call HR :926 6401233\n",
      "More Details: https://www.timesjobs.com/job-detail/2024-fresher-hiring-terminal-2-airport-job-kolkata-mumbai-pune-guwahati-lucknow-0-to-3-yrs-jobid-Sr9syG8nIOBzpSvf__PLUS__uAgZw==&source=srp\n",
      "\n",
      "Company: Dinab Recruitment Solutions\n",
      "Job Title: 2024 Fresher Hiring Terminal 2\n",
      "Posting Date: Posted today\n",
      "Skills: Airport Handling Operation Ground Handling|Ground Staff|customer services|cabin crew|air hostess|flight attendant|Hr9266325973\n",
      "More Details: https://www.timesjobs.com/job-detail/2024-fresher-hiring-terminal-2-airport-job-ahmedabad-nagpur-nasik-jaipur-jaisalmer-0-to-3-yrs-jobid-qdHM51GLn__SLASH__pzpSvf__PLUS__uAgZw==&source=srp\n",
      "\n",
      "Company: Dinab Recruitment Solutions\n",
      "Job Title: Regional Logistics Manager,Hiring\n",
      "Posting Date: Posted today\n",
      "Skills: Airport Management|Ground Staff|Cabin Crew|Air Hostess|Cargo Operations|Cargo Handling|Logistics Coordinator|Logistics Manager|Call HR :926 6401233\n",
      "More Details: https://www.timesjobs.com/job-detail/regional-logistics-manager-hiring-airports-airlines-bengaluru-bangalore-chennai-hyderabad-secunderabad-kolkata-pune-0-to-3-yrs-jobid-jlvZ9jphqyFzpSvf__PLUS__uAgZw==&source=srp\n",
      "\n",
      "Company: Dinab Recruitment Solutions\n",
      "Job Title: Logistic Supervisor/at Aviation\n",
      "Posting Date: Posted today\n",
      "Skills: Airport Management|Ground Staff|Cabin Crew|Air Hostess|Cargo Operations|Cargo Handling|Logistics Coordinator|Logistics Manager|Call HR :926 6401233\n",
      "More Details: https://www.timesjobs.com/job-detail/logistic-supervisor-at-aviation-airports-airlines-bengaluru-bangalore-hyderabad-secunderabad-pune-cochin-kochi-ernakulam-coimbatore-0-to-3-yrs-jobid-d__SLASH__HZKsdlgrpzpSvf__PLUS__uAgZw==&source=srp\n",
      "\n",
      "Company: Dinab Recruitment Solutions\n",
      "Job Title: Logistic Supervisor Job/at Aviation\n",
      "Posting Date: Posted today\n",
      "Skills: Airport Management|Ground Staff|Cabin Crew|Air Hostess|Cargo Operations|Cargo Handling|Logistics Coordinator|Logistics Manager|Call HR :926 6401233\n",
      "More Details: https://www.timesjobs.com/job-detail/logistic-supervisor-job-at-aviation-airports-airlines-ahmedabad-chandigarh-nagpur-jaipur-lucknow-0-to-3-yrs-jobid-ccvBoeFdvxpzpSvf__PLUS__uAgZw==&source=srp\n",
      "\n",
      "Company: Dinab Recruitment Solutions\n",
      "Job Title: Apply For IT Analyst Job at Airport\n",
      "Posting Date: Posted today\n",
      "Skills: Call HR :926 6401233|Business Analysis|Data Analysis|Data Base Administration|Call HR :926 6401233\n",
      "More Details: https://www.timesjobs.com/job-detail/apply-for-it-analyst-job-at-airport-airports-airlines-bengaluru-bangalore-chennai-hyderabad-secunderabad-mumbai-pune-0-to-3-yrs-jobid-a0w__SLASH__Ss47mM1zpSvf__PLUS__uAgZw==&source=srp\n",
      "\n",
      "Company: Dinab Recruitment Solutions\n",
      "Job Title: Apply For IT Analyst Job at Airport\n",
      "Posting Date: Posted today\n",
      "Skills: Business Analysis|Data Analysis|Data Base Administration|Call HR :926 6401233|IT Analyst\n",
      "More Details: https://www.timesjobs.com/job-detail/apply-for-it-analyst-job-at-airport-airports-airlines-vijayawada-mangalore-cochin-kochi-ernakulam-thiruvananthapuram-coimbatore-0-to-3-yrs-jobid-MxCGXAR6LF5zpSvf__PLUS__uAgZw==&source=srp\n",
      "\n",
      "Company: Dinab Recruitment Solutions\n",
      "Job Title: Visa & Documentation,Job\n",
      "Posting Date: Posted today\n",
      "Skills: Airport Handling Operation Ground Handling|Ground Staff|customer services|cabin crew|air hostess|flight attendant|Hr9266325973\n",
      "More Details: https://www.timesjobs.com/job-detail/visa-documentation-job-airport-job-ahmedabad-nagpur-nasik-jaipur-jaisalmer-0-to-3-yrs-jobid-k6jBbfD7__SLASH__IVzpSvf__PLUS__uAgZw==&source=srp\n",
      "\n",
      "Company: Dinab Recruitment Solutions\n",
      "Job Title: Urgent Hiring For IT Analyst\n",
      "Posting Date: Posted today\n",
      "Skills: Business Analysis|Data Analysis|Data Base Administration|Call HR :926 6401233|IT Analyst\n",
      "More Details: https://www.timesjobs.com/job-detail/urgent-hiring-for-it-analyst-airports-airlines-bengaluru-bangalore-chennai-hyderabad-secunderabad-mumbai-pune-0-to-3-yrs-jobid-__PLUS__FvukAN8tJ5zpSvf__PLUS__uAgZw==&source=srp\n",
      "\n",
      "Company: Dinab Recruitment Solutions\n",
      "Job Title: Urgent Hiring For IT Analyst\n",
      "Posting Date: Posted today\n",
      "Skills: Business Analysis|Data Analysis|Data Base Administration|Call HR :926 6401233|IT Analyst\n",
      "More Details: https://www.timesjobs.com/job-detail/urgent-hiring-for-it-analyst-airports-airlines-vijayawada-mangalore-cochin-kochi-ernakulam-thiruvananthapuram-coimbatore-0-to-3-yrs-jobid-3fmZaxxyCxVzpSvf__PLUS__uAgZw==&source=srp\n",
      "\n",
      "Company: Dinab Recruitment Solutions\n",
      "Job Title: Apply For IT Analyst Job at Airport\n",
      "Posting Date: Posted today\n",
      "Skills: Business Analysis|Data Analysis|Data Base Administration|Call HR :926 6401233|IT Analyst\n",
      "More Details: https://www.timesjobs.com/job-detail/apply-for-it-analyst-job-at-airport-airports-airlines-indore-nagpur-bhubaneshwar-lucknow-dehradun-0-to-3-yrs-jobid-Jhv46uOQGbVzpSvf__PLUS__uAgZw==&source=srp\n",
      "\n",
      "Company: Dinab Recruitment Solutions\n",
      "Job Title: Visa & Documentation\n",
      "Posting Date: Posted today\n",
      "Skills: Airport Handling Operation Ground Handling|Ground Staff|customer services|cabin crew|air hostess|flight attendant|Hr9266325973\n",
      "More Details: https://www.timesjobs.com/job-detail/visa-documentation-airport-job-kolkata-mumbai-pune-lucknow-varanasi-banaras-0-to-3-yrs-jobid-68FgxCF0hWpzpSvf__PLUS__uAgZw==&source=srp\n",
      "\n",
      "Company: Dinab Recruitment Solutions\n",
      "Job Title: Apply for Airport jobs - Ground Staff/Cabin Crew\n",
      "Posting Date: Posted today\n",
      "Skills: Airport Management|Ground Staff|Cabin Crew|Air Hostess|Cargo Operations|Cargo Handling|Logistics Coordinator|Logistics Manager|Air Ticketing\n",
      "More Details: https://www.timesjobs.com/job-detail/apply-for-airport-jobs-ground-staff-cabin-crew-airports-airlines-bengaluru-bangalore-hyderabad-secunderabad-mumbai-cochin-kochi-ernakulam-thiruvananthapuram-0-to-3-yrs-jobid-gb4L8GkB9sFzpSvf__PLUS__uAgZw==&source=srp\n",
      "\n",
      "Company: welingkar institute\n",
      "Job Title: Professor /Associate Professor / Assistant Professor  E-Business\n",
      "Posting Date: 1 day ago\n",
      "Skills: algorithms|artificial intelligence|sem|hadoop|big data|crm|python|mobile|machine learning|artificial neural networks|shopify\n",
      "More Details: https://www.timesjobs.com/job-detail/professor-associate-professor-assistant-professor-e-business-welingkar-institute-mumbai-0-to-3-yrs-jobid-zS1F2oXfzjVzpSvf__PLUS__uAgZw==&source=srp\n",
      "\n",
      "Waiting 10 seconds...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 70\u001b[0m\n\u001b[0;32m     68\u001b[0m time_wait \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWaiting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime_wait\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 70\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_wait\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# Function to extract skill required from job post\n",
    "def extract_skills(skills_container):\n",
    "    if skills_container:\n",
    "        skills = re.findall(r'<span[^>]*>(.*?)</span>', str(skills_container), re.DOTALL)\n",
    "        skills_list = [\n",
    "            skill.strip().replace(' / ', '/').replace('**   ', '').replace('  **', '').replace('amp', '')\n",
    "            for skill in skills if skill.strip()\n",
    "        ]\n",
    "        return skills_list\n",
    "    return []\n",
    "\n",
    "\n",
    "# function to extract data from website html\n",
    "def find_jobs():\n",
    "    try:\n",
    "        response = requests.get(\n",
    "            'https://www.timesjobs.com/candidate/job-search.html?searchType=Home_Search&from=submit&asKey=OFF&txtKeywords=&cboPresFuncArea=&cboWorkExp1=0&clusterName=CLUSTER_EXP'\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            html_text = response.text\n",
    "            soup = BeautifulSoup(html_text, 'lxml')\n",
    "            job_boxes = soup.find_all('li', class_='clearfix job-bx wht-shd-bx')\n",
    "\n",
    "            for job_box in job_boxes:\n",
    "                job_title = job_box.find('a').text.strip()\n",
    "                posting_date = job_box.find('span', class_='sim-posted').text.strip()\n",
    "                company_name = job_box.find('h3', class_='joblist-comp-name').text.strip()\n",
    "                more_details = job_box.a['href']\n",
    "                    \n",
    "                # Extract skills\n",
    "                skills_container = job_box.find('div', class_='more-skills-sections')\n",
    "                skills = extract_skills(skills_container)\n",
    "    \n",
    "                print(f\"Company: {company_name}\")\n",
    "                print(f\"Job Title: {job_title}\")\n",
    "                print(f\"Posting Date: {posting_date}\")            \n",
    "                print(f\"Skills: {'|'.join(skills)}\")\n",
    "                print(f\"More Details: {more_details}\\n\")\n",
    "                    \n",
    "        else:\n",
    "            print(\"failed to connect\")\n",
    "                  \n",
    "\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(\"Connection error. Retrying in 10 seconds...\")\n",
    "        time.sleep(10)\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(f\"HTTP error: {e}. Retrying in 10 seconds...\")\n",
    "        time.sleep(10)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Run find_jobs repeatedly with time intervals\n",
    "if __name__ == '__main__':\n",
    "    while True:\n",
    "        find_jobs()\n",
    "        time_wait = 10\n",
    "        print(f'Waiting {time_wait} seconds...')\n",
    "        time.sleep(time_wait)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the job keyword input once at the start\n",
    "print('Input Job keyword')\n",
    "job_keyword = input('>> ')\n",
    "print(f'Searching for keyword: {job_keyword}')\n",
    "\n",
    "# Function to extract skills required from job post\n",
    "def extract_skills(skills_container):\n",
    "    if skills_container:\n",
    "        # Using BeautifulSoup to parse the container directly instead of regex\n",
    "        skills = skills_container.find_all('span')\n",
    "        skills_list = [skill.get_text(strip=True).replace(' / ', '/').replace('amp', '') for skill in skills]\n",
    "        return skills_list\n",
    "    return []\n",
    "\n",
    "# Function to extract data from website HTML\n",
    "def find_jobs():\n",
    "    try:\n",
    "        response = requests.get(\n",
    "            'https://www.timesjobs.com/candidate/job-search.html?searchType=Home_Search&from=submit&asKey=OFF&txtKeywords=&cboPresFuncArea=&cboWorkExp1=0&clusterName=CLUSTER_EXP'\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Checking if the response status code is 200\n",
    "        if response.status_code == 200:\n",
    "            html_text = response.text\n",
    "            soup = BeautifulSoup(html_text, 'lxml')\n",
    "            job_boxes = soup.find_all('li', class_='clearfix job-bx wht-shd-bx')\n",
    "            \n",
    "            # Temporary list for current jobs\n",
    "            current_job_data = []\n",
    "\n",
    "            for job_box in job_boxes:\n",
    "                job_title = job_box.find('a').text.strip()\n",
    "                if job_keyword.casefold() in job_title.casefold():\n",
    "                    posting_date = job_box.find('span', class_='sim-posted').text.strip()\n",
    "                    company_name = job_box.find('h3', class_='joblist-comp-name').text.strip()\n",
    "                    more_details = job_box.a['href']\n",
    "                    \n",
    "                    # Extract skills\n",
    "                    skills_container = job_box.find('div', class_='more-skills-sections')\n",
    "                    skills = extract_skills(skills_container)\n",
    "\n",
    "                    # Append to list\n",
    "                    current_job_data.append({\n",
    "                        'company_name': company_name,\n",
    "                        'job_title': job_title,\n",
    "                        'posting_duration': posting_date,\n",
    "                        'skills': '|'.join(skills),\n",
    "                        'more_details': more_details\n",
    "                    })\n",
    "\n",
    "            # Check for existing CSV file\n",
    "            file_exists = os.path.isfile('job_data.csv')\n",
    "            \n",
    "            # Load existing data if CSV exists\n",
    "            if file_exists:\n",
    "                previous_data = pd.read_csv('job_data.csv')\n",
    "                current_data_df = pd.DataFrame(current_job_data)\n",
    "                \n",
    "                # Check if the current and previous data are identical\n",
    "                if previous_data.equals(current_data_df):\n",
    "                    print(\"No new data found; skipping CSV update.\")\n",
    "                    return  \n",
    "            \n",
    "            # Write new data to CSV if different\n",
    "            pd.DataFrame(current_job_data).to_csv('job_data.csv', index=False)\n",
    "            print(\"Data updated in CSV file.\")\n",
    "\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(\"Connection error. Retrying in 10 seconds...\")\n",
    "        time.sleep(10)\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(f\"HTTP error: {e}. Retrying in 10 seconds...\")\n",
    "        time.sleep(10)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Run find_jobs repeatedly with time intervals\n",
    "if __name__ == '__main__':\n",
    "    while True:\n",
    "        find_jobs()\n",
    "        time_wait = 10  # Time to wait before the next search\n",
    "        print(f'Waiting {time_wait} seconds...')\n",
    "        time.sleep(time_wait)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the job keyword input once at the start\n",
    "print('Input Job keyword')\n",
    "job_keyword = input('>> ')\n",
    "print(f'Searching for keyword: {job_keyword}')\n",
    "\n",
    "# Function to extract skills required from job post\n",
    "def extract_skills(skills_container):\n",
    "    if skills_container:\n",
    "        # Using BeautifulSoup to parse the container directly instead of regex\n",
    "        skills = skills_container.find_all('span')\n",
    "        skills_list = [skill.get_text(strip=True).replace(' / ', '/').replace('amp', '') for skill in skills]\n",
    "        return skills_list\n",
    "    return []\n",
    "\n",
    "# Function to extract data from website HTML\n",
    "def find_jobs():\n",
    "    try:\n",
    "        response = requests.get(\n",
    "            'https://www.timesjobs.com/candidate/job-search.html?searchType=Home_Search&from=submit&asKey=OFF&txtKeywords=&cboPresFuncArea=&cboWorkExp1=0&clusterName=CLUSTER_EXP'\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Checking if the response status code is 200\n",
    "        if response.status_code == 200:\n",
    "            html_text = response.text\n",
    "            soup = BeautifulSoup(html_text, 'lxml')\n",
    "            job_boxes = soup.find_all('li', class_='clearfix job-bx wht-shd-bx')\n",
    "            \n",
    "            # Temporary list for current jobs\n",
    "            current_job_data = []\n",
    "\n",
    "            for job_box in job_boxes:\n",
    "                job_title = job_box.find('a').text.strip()\n",
    "                if job_keyword.casefold() in job_title.casefold():\n",
    "                    posting_date = job_box.find('span', class_='sim-posted').text.strip()\n",
    "                    company_name = job_box.find('h3', class_='joblist-comp-name').text.strip()\n",
    "                    more_details = job_box.a['href']\n",
    "                    \n",
    "                    # Extract skills\n",
    "                    skills_container = job_box.find('div', class_='more-skills-sections')\n",
    "                    skills = extract_skills(skills_container)\n",
    "\n",
    "                    # Append to list\n",
    "                    current_job_data.append({\n",
    "                        'company_name': company_name,\n",
    "                        'job_title': job_title,\n",
    "                        'posting_duration': posting_date,\n",
    "                        'skills': '|'.join(skills),\n",
    "                        'more_details': more_details\n",
    "                    })\n",
    "\n",
    "            # Check for existing CSV file\n",
    "            file_exists = os.path.isfile('job_datas.csv')\n",
    "            \n",
    "            # Load existing data if CSV exists\n",
    "            if file_exists and os.stat(\"job_datas.csv\").st_size > 0:  # Check if the file has content\n",
    "                previous_data = pd.read_csv('job_datas.csv')\n",
    "                current_data_df = pd.DataFrame(current_job_data)\n",
    "                \n",
    "                # Check if the dataframes are identical\n",
    "                if previous_data.equals(current_data_df):\n",
    "                    print(\"No new data found; skipping CSV update.\")\n",
    "                    return\n",
    "            else:\n",
    "                print(\"No existing data found, creating a new CSV file.\")\n",
    "            \n",
    "            # Write new data to CSV if different\n",
    "            pd.DataFrame(current_job_data).to_csv('job_datas.csv', index=False)\n",
    "            print(\"Data updated in CSV file.\")\n",
    "\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(\"Connection error. Retrying in 10 seconds...\")\n",
    "        time.sleep(10)\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(f\"HTTP error: {e}. Retrying in 10 seconds...\")\n",
    "        time.sleep(10)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Run find_jobs repeatedly with time intervals\n",
    "if __name__ == '__main__':\n",
    "    while True:\n",
    "        find_jobs()\n",
    "        time_wait = 10  # Time to wait before the next search\n",
    "        print(f'Waiting {time_wait} seconds...')\n",
    "        time.sleep(time_wait)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 01:31:42,302 - INFO - Starting job search for keyword: analyst\n",
      "2024-11-05 01:31:48,249 - INFO - Found 25 new jobs matching 'analyst'\n",
      "2024-11-05 01:31:48,251 - INFO - Waiting 60 seconds before next search...\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Optional\n",
    "import logging\n",
    "from urllib.parse import quote\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('job_scraper.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "class TimesJobsScraper:\n",
    "    BASE_URL = 'https://www.timesjobs.com/candidate/job-search.html'\n",
    "    \n",
    "    def __init__(self, output_file: str = 'job_data.csv'):\n",
    "        self.output_file = output_file\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update({\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        })\n",
    "\n",
    "    def _get_search_url(self, keyword: str) -> str:\n",
    "        \"\"\"Construct search URL with proper encoding.\"\"\"\n",
    "        params = {\n",
    "            'searchType': 'personalizedSearch',\n",
    "            'from': 'submit',\n",
    "            'txtKeywords': keyword,\n",
    "            'cboPresFuncArea': '',\n",
    "        }\n",
    "        query_string = '&'.join(f\"{k}={quote(str(v))}\" for k, v in params.items())\n",
    "        return f\"{self.BASE_URL}?{query_string}\"\n",
    "\n",
    "    def _extract_skills(self, skills_container) -> List[str]:\n",
    "        \"\"\"Extract skills from the job posting.\"\"\"\n",
    "        if not skills_container:\n",
    "            return []\n",
    "        skills = skills_container.find_all('span')\n",
    "        return [skill.get_text(strip=True).replace(' / ', '/').replace('amp;', '') \n",
    "                for skill in skills]\n",
    "\n",
    "    def _parse_job_box(self, job_box, keyword: str) -> Optional[Dict]:\n",
    "        \"\"\"Parse individual job posting.\"\"\"\n",
    "        try:\n",
    "            job_title = job_box.find('a').text.strip()\n",
    "            if keyword.casefold() not in job_title.casefold():\n",
    "                return None\n",
    "\n",
    "            return {\n",
    "                'company_name': job_box.find('h3', class_='joblist-comp-name').text.strip(),\n",
    "                'job_title': job_title,\n",
    "                'posting_duration': job_box.find('span', class_='sim-posted').text.strip(),\n",
    "                'skills': '|'.join(self._extract_skills(job_box.find('div', class_='more-skills-sections'))),\n",
    "                'more_details': job_box.a['href'],\n",
    "                'scraped_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            }\n",
    "        except AttributeError as e:\n",
    "            logging.warning(f\"Error parsing job box: {e}\")\n",
    "            return None\n",
    "\n",
    "    def _update_csv(self, new_data: List[Dict]) -> bool:\n",
    "        \"\"\"Update CSV file with new job data, avoiding duplicates.\"\"\"\n",
    "        if not new_data:\n",
    "            logging.info(\"No new data to update\")\n",
    "            return False\n",
    "\n",
    "        new_df = pd.DataFrame(new_data)\n",
    "        \n",
    "        try:\n",
    "            if os.path.exists(self.output_file):\n",
    "                existing_df = pd.read_csv(self.output_file)\n",
    "                # Compare only relevant columns for duplicates\n",
    "                comparison_columns = ['company_name', 'job_title', 'more_details']\n",
    "                merged_df = pd.concat([existing_df, new_df]).drop_duplicates(\n",
    "                    subset=comparison_columns, \n",
    "                    keep='last'\n",
    "                )\n",
    "            else:\n",
    "                merged_df = new_df\n",
    "\n",
    "            merged_df.to_csv(self.output_file, index=False)\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error updating CSV: {e}\")\n",
    "            return False\n",
    "\n",
    "    def scrape_jobs(self, keyword: str) -> None:\n",
    "        \"\"\"Main function to scrape jobs.\"\"\"\n",
    "        url = self._get_search_url(keyword)\n",
    "        \n",
    "        try:\n",
    "            response = self.session.get(url, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            soup = BeautifulSoup(response.text, 'lxml')\n",
    "            job_boxes = soup.find_all('li', class_='clearfix job-bx wht-shd-bx')\n",
    "            \n",
    "            current_jobs = []\n",
    "            for job_box in job_boxes:\n",
    "                job_data = self._parse_job_box(job_box, keyword)\n",
    "                if job_data:\n",
    "                    current_jobs.append(job_data)\n",
    "            \n",
    "            if current_jobs:\n",
    "                if self._update_csv(current_jobs):\n",
    "                    logging.info(f\"Found {len(current_jobs)} new jobs matching '{keyword}'\")\n",
    "                else:\n",
    "                    logging.info(\"No new unique jobs found\")\n",
    "            else:\n",
    "                logging.info(f\"No jobs found matching '{keyword}'\")\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            logging.error(f\"Request failed: {e}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Unexpected error: {e}\")\n",
    "\n",
    "def main():\n",
    "    scraper = TimesJobsScraper()\n",
    "    keyword = input('Enter job keyword to search: ').strip()\n",
    "    \n",
    "    if not keyword:\n",
    "        logging.error(\"Keyword cannot be empty\")\n",
    "        return\n",
    "\n",
    "    logging.info(f\"Starting job search for keyword: {keyword}\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            scraper.scrape_jobs(keyword)\n",
    "            wait_time = 60  # 1 minute between searches\n",
    "            logging.info(f\"Waiting {wait_time} seconds before next search...\")\n",
    "            time.sleep(wait_time)\n",
    "        except KeyboardInterrupt:\n",
    "            logging.info(\"Scraping stopped by user\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Fatal error: {e}\")\n",
    "            break\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bs4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
